{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "V4EFYBUgPwyx",
   "metadata": {
    "id": "V4EFYBUgPwyx"
   },
   "source": [
    "# TensorFlow crash course\n",
    "### **PART 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vdiGzVGHPboe",
   "metadata": {
    "id": "vdiGzVGHPboe"
   },
   "source": [
    "### MNIST Dataset\n",
    "#### A dataset of images about digits containing 10 classes from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "jI-HjnCsdpEi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jI-HjnCsdpEi",
    "outputId": "8ca7b70a-f5cf-48b0-ef21-4ca1b71faf78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (1000, 784) (10000, 10) (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
    "#  Using less data to speed up training because the main concept isn't about data management\n",
    "X_train, X_test = X_train[:10000], X_test[:1000]\n",
    "y_train, y_test = y_train[:10000], y_test[:1000]\n",
    "X_train, X_test = X_train.reshape(-1, 28*28) / 255.0, X_test.reshape(-1, 28*28) / 255.0\n",
    "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Jz2xroeNn3V",
   "metadata": {
    "id": "1Jz2xroeNn3V"
   },
   "source": [
    "### Simple DNN(Deep Neural Network) in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6zARgCmtNva8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zARgCmtNva8",
    "outputId": "a6c75ad1-bb4f-417c-a2aa-85a93b7a1acb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 2s 3ms/step - loss: 1.8058 - accuracy: 0.4708 - val_loss: 1.2073 - val_accuracy: 0.6910\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7502 - accuracy: 0.8106 - val_loss: 0.6073 - val_accuracy: 0.8400\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4687 - accuracy: 0.8746 - val_loss: 0.4760 - val_accuracy: 0.8570\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3831 - accuracy: 0.8930 - val_loss: 0.4150 - val_accuracy: 0.8810\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.9054 - val_loss: 0.3898 - val_accuracy: 0.8860\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3049 - accuracy: 0.9142 - val_loss: 0.3783 - val_accuracy: 0.8840\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2844 - accuracy: 0.9196 - val_loss: 0.3592 - val_accuracy: 0.8900\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2650 - accuracy: 0.9252 - val_loss: 0.3288 - val_accuracy: 0.9020\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2476 - accuracy: 0.9311 - val_loss: 0.3254 - val_accuracy: 0.9080\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2339 - accuracy: 0.9345 - val_loss: 0.3052 - val_accuracy: 0.9150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.9150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.9150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30523860454559326, 0.9150000214576721]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "dnn = Sequential()\n",
    "dnn.add(Dense(128, input_shape=(784, ), activation=\"relu\"))\n",
    "dnn.add(Dense(64, activation=\"relu\"))\n",
    "dnn.add(Dense(32, activation=\"relu\"))\n",
    "dnn.add(Dense(10, activation=\"softmax\"))\n",
    "dnn.compile(loss=\"categorical_crossentropy\", optimizer=SGD(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "dnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "dnn.evaluate(X_test, y_test, batch_size=32)\n",
    "dnn.save(\"custom_component_model.h5\")\n",
    "dnn = load_model(\"custom_component_model.h5\")\n",
    "dnn.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eUSvKSyrPJi1",
   "metadata": {
    "id": "eUSvKSyrPJi1"
   },
   "source": [
    "### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "kK084GelPNR4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kK084GelPNR4",
    "outputId": "64bc0471-9ea6-4294-95b5-6676724aea28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 20.5487 - accuracy: 0.7977 - val_loss: 11.5133 - val_accuracy: 0.8850\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 7.6653 - accuracy: 0.9290 - val_loss: 8.0523 - val_accuracy: 0.9160\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 5.2680 - accuracy: 0.9515 - val_loss: 6.7493 - val_accuracy: 0.9370\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 6.0429 - accuracy: 0.9492 - val_loss: 7.1796 - val_accuracy: 0.9350\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 3.5311 - accuracy: 0.9663 - val_loss: 5.8483 - val_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.5812 - accuracy: 0.9751 - val_loss: 6.9002 - val_accuracy: 0.9290\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0221 - accuracy: 0.9802 - val_loss: 7.4061 - val_accuracy: 0.9440\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4726 - accuracy: 0.9862 - val_loss: 7.9566 - val_accuracy: 0.9340\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7181 - accuracy: 0.9833 - val_loss: 6.7850 - val_accuracy: 0.9430\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8426 - accuracy: 0.9912 - val_loss: 7.4807 - val_accuracy: 0.9340\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4807 - accuracy: 0.9340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.48069429397583, 0.9340000152587891]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Implement the log loss function with optional <My loss function choice>\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "class LogLoss(Loss):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    #  The main formula of the loss function must be written here\n",
    "    #  If your loss function contains any hyperparameters, initialize it in __init__\n",
    "    def call(self, y_true, y_pred):\n",
    "        loss = -tf.reduce_sum(y_true * tf.math.log(y_pred))\n",
    "        return loss\n",
    "\n",
    "    #  This function is supposed to map all hyperparameters (including yours) as a dict\n",
    "    #  When saving the model this function helps save your hyperparameters in a json file\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}\n",
    "\n",
    "dnn = Sequential()\n",
    "dnn.add(Dense(128, input_shape=(784, ), activation=\"relu\"))\n",
    "dnn.add(Dense(64, activation=\"relu\"))\n",
    "dnn.add(Dense(32, activation=\"relu\"))\n",
    "dnn.add(Dense(10, activation=\"softmax\"))\n",
    "dnn.compile(loss=LogLoss(), optimizer=SGD(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "dnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "dnn.save(\"custom_component_model.h5\")\n",
    "#  Use the custom_objects argument to load the loss function along its hyperparameters\n",
    "dnn = load_model(\"custom_component_model.h5\", custom_objects={\"LogLoss\":LogLoss})\n",
    "dnn.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gWGkwi8WAY8m",
   "metadata": {
    "id": "gWGkwi8WAY8m"
   },
   "source": [
    "### Custom layer components\n",
    "### *Activation function*\n",
    "### *Regularizer*\n",
    "### *Initializer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wfE3LbCuAzd-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfE3LbCuAzd-",
    "outputId": "d4aca683-30db-497d-be5a-b710dfd1426c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 17.1951 - accuracy: 0.8307 - val_loss: 10.8473 - val_accuracy: 0.8950\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 6.2465 - accuracy: 0.9390 - val_loss: 7.9605 - val_accuracy: 0.9200\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 4.2218 - accuracy: 0.9574 - val_loss: 6.1037 - val_accuracy: 0.9360\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.7027 - accuracy: 0.9732 - val_loss: 6.4421 - val_accuracy: 0.9420\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.0159 - accuracy: 0.9802 - val_loss: 7.6799 - val_accuracy: 0.9240\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.7113 - accuracy: 0.9823 - val_loss: 6.7592 - val_accuracy: 0.9380\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4618 - accuracy: 0.9863 - val_loss: 8.1577 - val_accuracy: 0.9440\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9531 - accuracy: 0.9909 - val_loss: 7.2370 - val_accuracy: 0.9420\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2095 - accuracy: 0.9880 - val_loss: 11.3001 - val_accuracy: 0.9060\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6660 - accuracy: 0.9943 - val_loss: 7.1760 - val_accuracy: 0.9450\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.1760 - accuracy: 0.9450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.175950050354004, 0.9449999928474426]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Every structure is going to be like the previous LogLoss structure\n",
    "#  Activation function : mish\n",
    "#  Regularizer : L2 \n",
    "#  Initializer : LeCun\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from tensorflow.keras.regularizers import Regularizer\n",
    "from tensorflow.keras.initializers import Initializer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "\n",
    "class Mish(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def call(self, z):\n",
    "        return tf.multiply(z, tf.math.tanh(self.softplus(z)))\n",
    "\n",
    "    def softplus(self, z):\n",
    "        return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}\n",
    "\n",
    "class L2(Regularizer):\n",
    "    def __init__(self, reg=0.0002):\n",
    "        self.reg = reg\n",
    "    \n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.multiply(self.reg, weights) ** 2)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"reg\":self.reg}\n",
    "\n",
    "class LeCun(Initializer):\n",
    "    def __call__(self, shape, dtype=tf.float32):\n",
    "        limit = tf.sqrt(3 / float(shape[0]))\n",
    "        return tf.random.normal(shape, stddev=limit, dtype=dtype)\n",
    "\n",
    "'''Note : You must implement the call() method for losses, layers (including activa‚Äê\n",
    "tion functions), and models, or the __call__() method for regularizers, initializers,\n",
    "and constraints'''\n",
    "\n",
    "dnn = Sequential()\n",
    "dnn.add(Dense(128, input_shape=(784, ), activation=Mish(), kernel_regularizer=L2(0.0002), kernel_initializer=LeCun))\n",
    "dnn.add(Dense(64, activation=Mish(), kernel_regularizer=L2(0.0002)))\n",
    "dnn.add(Dense(32, activation=Mish(), kernel_regularizer=L2(0.0002)))\n",
    "dnn.add(Dense(10, activation=\"softmax\"))\n",
    "dnn.compile(loss=LogLoss(), optimizer=SGD(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "dnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "dnn.save(\"custom_component_model.h5\")\n",
    "dnn = load_model(\"custom_component_model.h5\", custom_objects={\"LogLoss\":LogLoss, \"Mish\":Mish, \"L2\":L2, \"LeCun\":LeCun})\n",
    "dnn.evaluate(X_test, y_test, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TF_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
