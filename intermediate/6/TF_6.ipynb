{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "TF_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4EFYBUgPwyx"
      },
      "source": [
        "# TensorFlow crash course\n",
        "### **PART 6**"
      ],
      "id": "V4EFYBUgPwyx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouoUgugI4AD"
      },
      "source": [
        "### Autodiff (**TensorFlowâ€™s auto differentiation**)"
      ],
      "id": "_ouoUgugI4AD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqndoH4UJHXZ",
        "outputId": "d869d6ef-b64f-435e-d4f2-ad8bdad787d0"
      },
      "source": [
        "#  We use Tensorflow's autodiff to compute derivatives\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def func(W1, W2): #  Our simple mathmatical function\n",
        "    return 3 * W1 ** 2 + 2 * W1 * W2\n",
        "\n",
        "W1, W2 = tf.Variable(5.), tf.Variable(3.)\n",
        "with tf.GradientTape() as tape: #  Records every operation the variables go through automatically\n",
        "    z = func(W1, W2)\n",
        "\n",
        "gradients = tape.gradient(z, [W1, W2]) #  Compute the gradients of the result z based on both variables [w1, w2]\n",
        "print(gradients)"
      ],
      "id": "SqndoH4UJHXZ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvCOHG64Qmi5"
      },
      "source": [
        "### Auto erasing"
      ],
      "id": "EvCOHG64Qmi5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCWxSNhrW2y2",
        "outputId": "75593363-f05c-46ec-d608-0fffac636011"
      },
      "source": [
        "#  The tape is automatically erased immediately after you call its gradient() method\n",
        "#  To prevent the above issue we use a tiny magic\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape: # Notice that we added the presistent argument\n",
        "    z = func(W1, W2)\n",
        "\n",
        "gradients = tape.gradient(z, [W1, W2])\n",
        "print(gradients)\n",
        "gradients = tape.gradient(z, [W1, W2]) #  Works fine now\n",
        "print(gradients)"
      ],
      "id": "eCWxSNhrW2y2",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]\n",
            "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SViF75HBaHXY"
      },
      "source": [
        "### Autodiff for constants"
      ],
      "id": "SViF75HBaHXY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwsmw4-IaLlB",
        "outputId": "94266351-32d0-4586-ace7-8cff5de7843b"
      },
      "source": [
        "C1, C2 = tf.constant(5.), tf.constant(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(C1)\n",
        "    tape.watch(C2)\n",
        "    z = func(C1, C2)\n",
        "\n",
        "gradients = tape.gradient(z, [C1, C2])\n",
        "print(gradients)"
      ],
      "id": "Lwsmw4-IaLlB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30sj5Mj1dRcx"
      },
      "source": [
        "### Autodiff for vectors"
      ],
      "id": "30sj5Mj1dRcx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhuKN4YrdVea",
        "outputId": "e4afa6ba-ab86-4a9f-db81-39c9d0c68d79"
      },
      "source": [
        "V1, V2 = tf.Variable([1., 3., 5., 7.]), tf.Variable([2., 4., 6., 8.])\n",
        "with tf.GradientTape() as tape:\n",
        "    z = func(V1, V2)\n",
        "\n",
        "jacobians = tape.jacobian(z, [V1, V2])\n",
        "print(jacobians)"
      ],
      "id": "vhuKN4YrdVea",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
            "array([[10.,  0.,  0.,  0.],\n",
            "       [ 0., 26.,  0.,  0.],\n",
            "       [ 0.,  0., 42.,  0.],\n",
            "       [ 0.,  0.,  0., 58.]], dtype=float32)>, <tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
            "array([[ 2.,  0.,  0.,  0.],\n",
            "       [ 0.,  6.,  0.,  0.],\n",
            "       [ 0.,  0., 10.,  0.],\n",
            "       [ 0.,  0.,  0., 14.]], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoDRJ7BcgqKZ"
      },
      "source": [
        "### Custom gradient"
      ],
      "id": "qoDRJ7BcgqKZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdFH2ZYIgsA3",
        "outputId": "878abfa1-adb7-41c2-aaf9-9c3a67e0bf94"
      },
      "source": [
        "#  We'll implement a custom gradient for the sinc function\n",
        "#  In order to do such a thing, we have to use the tf.custom_gradient decorator\n",
        "\n",
        "@tf.custom_gradient\n",
        "def sinc(x):\n",
        "    sin = tf.sin(x)\n",
        "    cos = tf.cos(x)\n",
        "    eps = tf.constant(1e-5)\n",
        "    def sinc_gradient(grad):\n",
        "        return (x * cos - sin) / (tf.square(x)+eps)\n",
        "    return sin / (x+eps), sinc_gradient \n",
        "\n",
        "x = tf.Variable(1.)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = sinc(x)\n",
        "\n",
        "gradients = tape.gradient(z, x) \n",
        "print(gradients)"
      ],
      "id": "bdFH2ZYIgsA3",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(-0.30116567, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}